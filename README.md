<h1 align="center">NarrativeAI</h1>
 <p align="center">
  <img src="https://img.shields.io/badge/Python-FFD43B?style=for-the-badge&logo=python&logoColor=blue"> <img src="https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white"> <img src="https://img.shields.io/badge/GPT-75AB9E?style=for-the-badge&logo=data:image/png;base64,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">
</p>

NarrativeAI is a project that uses machine learning to generate new transcripts for the Person of Interest TV series. The project is based on the idea of training a language model on the existing transcripts of the show and using it to generate new ones.

<p align="center">
<img width="470" alt="Transcript" src="https://user-images.githubusercontent.com/28122432/221449543-74b5933b-3b1b-4a61-b42f-a8c23c463916.png">
</p>

## Getting Started

### Prerequisites

To run this project, you will need:

* Python 3.6 or higher
* The transcripts for the Person of Interest TV series (for training the language model)

### Installation and Setup

1. Clone this repository to your local machine.

```
git clone https://github.com/Scylidose/NarrativeAI.git
```

2. Create and activate a new virtual environment:

```
python3 -m venv env
source env/bin/activate # on Linux or macOS
.\env\Scripts\activate # on Windows
```

3. Install the required Python packages:

```
pip3 install -r requirements.txt
```

This will install all the necessary dependencies, including `transformers`, which provides an interface for using the pre-trained GPT-NEO model.

Now that you have set up your environment, you can proceed to running the scripts to generate new transcripts using the pre-trained model.

#### Notes 

- I use the GPT-NEO model instead of the newer ones for cost, availability and complexity reasons.


## Usage

### Train the model

#### Description

To train the language model, you can use the `train_model.py` script. This script trains a GPT-Neo model on input text data and saves the trained model to a specified directory.

```
python3 train_model.py [-h] [--model_name MODEL_NAME] [--batch_size BATCH_SIZE]
                      [--epochs EPOCHS] [--learning_rate LEARNING_RATE]
                      [--weight_decay WEIGHT_DECAY]
                      train_data_dir eval_data_dir model_dir
```

#### Arguments

- `train_data_dir`: The directory containing the cleaned input training data.
- `eval_data_dir`: The directory containing the cleaned input eval data.
- `model_dir`: The directory to save the trained model and training logs.
- `--model_name`: The name of the pretrained GPT-Neo model to use. Default is EleutherAI/gpt-neo-1.3B.
- `--batch_size`: The number of training samples per batch. Default is 4.
- `--epochs`: The number of times to iterate over the training data. Default is 1.
- `--learning_rate`: The learning rate for the optimizer. Default is 2e-5.
- `--weight_decay`: The amount of weight decay to apply during training. Default is 0.01.

#### Example

```
python3 train_model.py data/person_of_interest/train/ data/person_of_interest/eval/ models/
```

### Generate Script

#### Description 

To generate new transcripts using the trained model, you can use the `generate_script.py` script. This script generates new text based on a given prompt using a pre-trained transformer model. The generated text is saved to a specified directory.

```
python3 generate_script.py [-h] [--max_length MAX_LENGTH]
                          [--num_sequences NUM_SEQUENCES] [--do_sample DO_SAMPLE]
                          model_dir results_dir prompt [prompt ...]
```

#### Arguments
- `model_dir`: Path to the directory where the pre-trained model is stored.
- `results_dir`: Path to the directory where the generated text should be stored.
- `prompt`: The prompt to generate new text from.
- `--max_length`: The maximum number of tokens to generate. Default is 10000.
- `--num_sequences`: The number of independent sequences to generate for each prompt. Default is 1.
- `--do_sample`: Whether to use sampling or greedy decoding to generate new text. Default is True.

#### Example

```
python3 generate_script.py models/ results/ "You are being watched." --num_sequences 100
```

### All together 

To execute all the step (preprocessing, training and generating) in one command you can simply use the script:

```
python3 main.py
```

### Folder Structure

The following is the recommended folder structure for this project:

```
├── data
│   └── person_of_interest
│       ├── train
│       │   ├── raw
│       │   │   ├── season_1
│       │   │   │   ├── episode_1.txt
│       │   │   │   ├── ...
│       │   │   │── season_2
│       │   │   │── ...
│       │   └── cleaned
│       │       ├── season_1
│       │       │   ├── episode_20.txt
│       │       │   ├── ...
│       │       │── season_2
│       │       │── ...
│       │   
│       └── eval
│           ├── raw
│           │   ├── season_1
│           │   │   ├── episode_20.txt
│           │   │   ├── ...
│           │   │── season_2
│           │   │── ...
│           └── cleaned
│               ├── season_1
│               │   ├── episode_20.txt
│               │   ├── ...
│               │── season_2
│               │── ...
├── models
│
├── results
│
├── train_model.py
├── generate_script.py
├── preprocess_text.py
├── .gitignore
├── requirements.txt
└── README.md
```

The `data` directory should contain the transcripts for the TV series, organized by season and episode.  
The `models` directory should contain the trained language models, organized by model name.  
The `results` directory should contain the generated text, outputed by the trained and saved model.  
The `preprocess_text.py` is used to preprocess the text applying diverse operations  
The `train_model.py` and `generate_script.py` scripts are used for training and generating text, respectively.  
The `.gitignore` file specifies files and directories that should be ignored by Git.  
The `requirements.txt` file list all the necessary packages to run the project.  
The `README.md` file is the documentation for the project.

## Contributing

Contributions to this project are welcome. If you find a bug, have a feature request, or want to contribute code, please open an issue or pull request on the project's GitHub page.

## License

This project is licensed under the MIT License. See the `LICENSE` file for details.
